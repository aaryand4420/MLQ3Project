# -*- coding: utf-8 -*-
"""q3 project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GsQxN6v0FWqB2TlUzPWAn63dxWbM0Qqy
"""

# imports
from PIL import Image
import numpy as np
import cv2
from google.colab.patches import cv2_imshow
from sklearn.cluster import KMeans

from google.colab import drive
drive.mount('/content/drive')

"""# Image"""

# obtain the image and prepare for testing
test = cv2.imread('/content/drive/MyDrive/Buoys/buoys10.jpg', 1)
# test = cv2.medianBlur(test, 51)
test = cv2.resize(test, (100, 100))
test = cv2.cvtColor(test, cv2.COLOR_BGR2LAB)
cv2_imshow(test)
im = test
print(im.shape)

# obtain pixel arrays and superpixel objects, complete kmeans
pix2d = np.array(im)
pix = pix2d.reshape(-1, 3)
pix2d_2 = np.empty((pix2d.shape[0], pix2d.shape[1]), tuple)
superpixels = np.empty((pix2d.shape[0] * pix2d.shape[1], 3))
model = KMeans(n_clusters = 8).fit(pix)
centers = model.cluster_centers_.astype(int)
labels = model.predict(pix)
labels2d = labels.reshape(pix2d.shape[0], pix2d.shape[1])

index = 0
for x in range(pix2d.shape[0]):
    for y in range(pix2d.shape[1]):
        pix2d_2[x, y] = tuple(centers[labels2d[x, y]])
        superpixels[index] = np.array([x, y, labels2d[x, y]])
        index += 1

# display new kmeans image
im_2 = Image.new('RGB', (100, 100))
im_2.putdata(pix2d_2.reshape(-1))
# im_2.save("{}.png".format('buoy_kmeans'), "PNG")
display(im_2)

"""# Plot"""

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

rand_mask = np.full(pix.shape[0], False)
rand_mask[:1000] = True
np.random.shuffle(rand_mask)
sample = pix[rand_mask]
sample

fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.scatter(sample[:,0], sample[:,1], sample[:,2], c=labels[rand_mask])

super_sample = superpixels[rand_mask]
fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.scatter(super_sample[:,0], super_sample[:,1], super_sample[:,2], c=labels[rand_mask])

"""# See"""

pixdict = {tuple(c): [] for c in centers} #

for x in range(pix2d.shape[0]): 
  for y in range(pix2d.shape[1]):
    pixdict[pix2d_2[x, y]].append([x, y])
for c in pixdict:
  pixdict[c] = np.array(pixdict[c])

row, col = 2, 4

fig, axs = plt.subplots(row, col) 

for i, c in enumerate(pixdict):
  rand_mask = np.full(pixdict[c].shape[0], False)
  rand_mask[:250] = True
  np.random.shuffle(rand_mask)
  sample = pixdict[c][rand_mask]
  axs[i//col, i%col].set_ylim(pix2d.shape[0], 0)
  axs[i//col, i%col].set_xlim(0, pix2d.shape[1])
  axs[i//col, i%col].scatter(sample[:, 1], sample[:,0], color=np.array(c)/255, s=4)

"""#Experiment"""

from google.colab.patches import cv2_imshow

# https://www.pyimagesearch.com/2018/07/16/opencv-saliency-detection/
saliency = cv2.saliency.StaticSaliencySpectralResidual_create()
(success, saliencyMap) = saliency.computeSaliency(im)
saliencyMap = (saliencyMap * 255).astype("uint8")
cv2_imshow(im)
cv2_imshow(saliencyMap)

saliency = cv2.saliency.StaticSaliencyFineGrained_create()
(success, saliencyMap) = saliency.computeSaliency(im)
saliencyMap = (saliencyMap * 255).astype("uint8")
threshMap = cv2.threshold(saliencyMap.astype("uint8"), 0, 255,
	cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]

cv2_imshow(im)
cv2_imshow(saliencyMap)
cv2_imshow(threshMap)

"""# Cluster"""

# obtain standard deviations
stds = set()
for c in pixdict:
  points = pixdict[c]
  x_avg = np.average(points[:,0])
  y_avg = np.average(points[:,1])
  distances = np.empty((len(points)))
  for i in range(len(points)):
    distances[i] = ((points[i,0]-x_avg)**2+(points[i,1]-y_avg)**2)**0.5
  std = np.std(distances)
  stds.add((std, c))

# obtain all objects with std under tolerance
print(sorted(stds))
best = [obj for obj in sorted(stds) if obj[0] < 11]
if best == []:
  best = sorted(stds)[0:3]
best_colors = [b[1] for b in best]

# recolor image with detected objects
pix2d_algo = np.copy(pix2d_2)

obj_colors = [(255, 95, 31), (255, 240, 31), (125, 249, 255), (0, 255, 255), (255, 0, 255), (255, 255, 0)]

for i in range(len(best)):
  for pair in pixdict[best_colors[i]]:
    pix2d_algo[pair[0], pair[1]] = obj_colors[i]

'''for color in pixdict:
  if color not in best_colors:
    for pair in pixdict[color]:
      pix2d_algo[pair[0], pair[1]] = '''

pix2d_algo.shape

# display detected objects
im_algo = Image.new('RGB', (100, 100))
im_algo.putdata(pix2d_algo.reshape(-1))
display(im_2)
display(im_algo)

# show color palette of the image (changed)

palette = np.array([x for x in pixdict.keys()])
from skimage import io

indeces = np.random.randint(0, len(palette), size=(1, 8))
io.imshow(palette[indeces])

